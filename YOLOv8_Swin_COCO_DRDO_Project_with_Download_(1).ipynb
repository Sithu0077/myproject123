{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sithu0077/myproject123/blob/main/YOLOv8_Swin_COCO_DRDO_Project_with_Download_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZJWq_8S_Spi"
      },
      "source": [
        "# ðŸ” DRDO Project: YOLOv8 + Swin Transformer for Detection & Classification\n",
        "\n",
        "This notebook combines **YOLOv8** for object detection and **Swin Transformers** for classification using **COCO 2017**, an inbuilt PyTorch dataset."
      ],
      "id": "KZJWq_8S_Spi"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install Dependencies\n",
        "!pip install -q ultralytics timm torchvision pycocotools"
      ],
      "metadata": {
        "id": "WRqpc9kSAFsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2b2d41e-0bfc-45e0-cb06-f80a9f6bfd7e"
      },
      "id": "WRqpc9kSAFsc",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ViKeW1S_Spo",
        "outputId": "a33f562c-9b79-4b78-e6e6-76178b2436cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Import Libraries\n",
        "from ultralytics import YOLO\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from pycocotools.coco import COCO"
      ],
      "id": "3ViKeW1S_Spo"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vZ0_5dx_Spp",
        "outputId": "18ac6672-472e-4843-f896-f54ac7379fa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-16 09:14:31--  http://images.cocodataset.org/zips/train2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.89.204, 52.216.10.3, 52.217.141.105, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.89.204|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19336861798 (18G) [application/zip]\n",
            "Saving to: â€˜train2017.zipâ€™\n",
            "\n",
            "train2017.zip       100%[===================>]  18.01G  53.4MB/s    in 6m 39s  \n",
            "\n",
            "2025-05-16 09:21:10 (46.2 MB/s) - â€˜train2017.zipâ€™ saved [19336861798/19336861798]\n",
            "\n",
            "--2025-05-16 09:24:54--  http://images.cocodataset.org/zips/val2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.49.105, 54.231.131.49, 52.216.28.204, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.49.105|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 815585330 (778M) [application/zip]\n",
            "Saving to: â€˜val2017.zipâ€™\n",
            "\n",
            "val2017.zip         100%[===================>] 777.80M  59.3MB/s    in 14s     \n",
            "\n",
            "2025-05-16 09:25:08 (56.3 MB/s) - â€˜val2017.zipâ€™ saved [815585330/815585330]\n",
            "\n",
            "--2025-05-16 09:25:20--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 3.5.3.112, 52.217.195.25, 52.216.222.73, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|3.5.3.112|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252907541 (241M) [application/zip]\n",
            "Saving to: â€˜annotations_trainval2017.zipâ€™\n",
            "\n",
            "annotations_trainva 100%[===================>] 241.19M  60.4MB/s    in 4.5s    \n",
            "\n",
            "2025-05-16 09:25:25 (54.0 MB/s) - â€˜annotations_trainval2017.zipâ€™ saved [252907541/252907541]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download COCO 2017 Dataset (Optional: ~20GB total)\n",
        "!mkdir -p coco && cd coco && \\\n",
        "wget http://images.cocodataset.org/zips/train2017.zip && unzip -q train2017.zip && \\\n",
        "wget http://images.cocodataset.org/zips/val2017.zip && unzip -q val2017.zip && \\\n",
        "wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip && unzip -q annotations_trainval2017.zip\n"
      ],
      "id": "7vZ0_5dx_Spp"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu9wPKvj_Spp",
        "outputId": "62d3d37f-dc6c-4591-de63-79b240c2002c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=17.63s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.48s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "from pycocotools.coco import COCO\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Custom COCO Dataset class\n",
        "class CocoDataset(Dataset):\n",
        "    def __init__(self, root, annFile, transform=None):\n",
        "        self.root = root\n",
        "        self.coco = COCO(annFile)\n",
        "        self.ids = list(self.coco.imgs.keys())\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_id = self.ids[index]\n",
        "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
        "        target = self.coco.loadAnns(ann_ids)\n",
        "        path = self.coco.loadImgs(img_id)[0]['file_name']\n",
        "\n",
        "        img = Image.open(os.path.join(self.root, path)).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        # For classification, use the first object's category\n",
        "        label = target[0]['category_id'] if target else 0\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = CocoDataset(root='coco/train2017', annFile='coco/annotations/instances_train2017.json', transform=transform)\n",
        "test_dataset = CocoDataset(root='coco/val2017', annFile='coco/annotations/instances_val2017.json', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "id": "vu9wPKvj_Spp"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ypLgIqo_Spq",
        "outputId": "7a90edfe-73d7-42ff-f310-71913600ce88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt to 'yolov8m.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49.7M/49.7M [00:00<00:00, 311MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Load YOLOv8 Model\n",
        "yolo_model = YOLO(\"yolov8m.pt\")"
      ],
      "id": "9ypLgIqo_Spq"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "10747be1676e466aa95f975b00ebaf93",
            "ac7df05ad0484e4bbba239de38d9bacf",
            "aab1f92903f94a54b9f919eb6c99869b",
            "fafacc61af604907987350e7be7ce6ac",
            "5b1caed540ae4e36bcb436cf62a2b10d",
            "31ddca15c79241ffb12132380f288635",
            "51b1ff2bb81a4af380700a9fb5733443",
            "0f245014906841f18703584b461b817d",
            "def7d6fafef0415499bf074f28a1c487",
            "2f70cca418584c4180193fdc0a3def50",
            "4e62942f2cd64aa9bc4f5e26cf52dcdc"
          ]
        },
        "id": "o6jOGE2__Spr",
        "outputId": "79a9cac1-ca19-43bd-bb78-2df495bb4b53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10747be1676e466aa95f975b00ebaf93"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Step 5: Load Pretrained Swin Transformer\n",
        "swin_model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True, num_classes=91)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "swin_model = swin_model.to(device)"
      ],
      "id": "o6jOGE2__Spr"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FoFr0JuA_Sps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3af9760b-cbb1-441f-9ff4-5fb067cf26da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.4640\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Train Swin Transformer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(swin_model.parameters(), lr=0.0001)\n",
        "\n",
        "epochs = 1\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = swin_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")"
      ],
      "id": "FoFr0JuA_Sps"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "s0vYceI0_Spt"
      },
      "outputs": [],
      "source": [
        "# Step 7: Define Combined Inference\n",
        "def combined_inference(image_tensor):\n",
        "    pil_img = transforms.ToPILImage()(image_tensor)\n",
        "    pil_img.save(\"temp.jpg\")\n",
        "    print(\"YOLOv8 Detection Results:\")\n",
        "    yolo_model(\"temp.jpg\", show=True)\n",
        "    image_tensor = image_tensor.unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = swin_model(image_tensor)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "    classes = [str(i) for i in range(91)]\n",
        "    print(f\"Swin Transformer Classification: {classes[predicted.item()]}\")"
      ],
      "id": "s0vYceI0_Spt"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TYAxZxqs_Spu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5889b091-c67f-4eb5-b7fe-f94ad57936a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8 Detection Results:\n",
            "WARNING âš ï¸ Environment does not support cv2.imshow() or PIL Image.show()\n",
            "\n",
            "\n",
            "image 1/1 /content/temp.jpg: 640x640 1 bicycle, 5 cars, 36.5ms\n",
            "Speed: 45.6ms preprocess, 36.5ms inference, 253.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Swin Transformer Classification: 2\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Run Inference\n",
        "img, label = test_dataset[4]\n",
        "combined_inference(img)"
      ],
      "id": "TYAxZxqs_Spu"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ocGW70An_Spv"
      },
      "outputs": [],
      "source": [
        "# Step 9: Save Model\n",
        "torch.save(swin_model.state_dict(), 'swin_coco.pth')"
      ],
      "id": "ocGW70An_Spv"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "10747be1676e466aa95f975b00ebaf93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac7df05ad0484e4bbba239de38d9bacf",
              "IPY_MODEL_aab1f92903f94a54b9f919eb6c99869b",
              "IPY_MODEL_fafacc61af604907987350e7be7ce6ac"
            ],
            "layout": "IPY_MODEL_5b1caed540ae4e36bcb436cf62a2b10d"
          }
        },
        "ac7df05ad0484e4bbba239de38d9bacf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31ddca15c79241ffb12132380f288635",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_51b1ff2bb81a4af380700a9fb5733443",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "aab1f92903f94a54b9f919eb6c99869b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f245014906841f18703584b461b817d",
            "max": 114286722,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_def7d6fafef0415499bf074f28a1c487",
            "value": 114286722
          }
        },
        "fafacc61af604907987350e7be7ce6ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f70cca418584c4180193fdc0a3def50",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4e62942f2cd64aa9bc4f5e26cf52dcdc",
            "value": "â€‡114M/114Mâ€‡[00:00&lt;00:00,â€‡190MB/s]"
          }
        },
        "5b1caed540ae4e36bcb436cf62a2b10d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31ddca15c79241ffb12132380f288635": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51b1ff2bb81a4af380700a9fb5733443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f245014906841f18703584b461b817d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "def7d6fafef0415499bf074f28a1c487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f70cca418584c4180193fdc0a3def50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e62942f2cd64aa9bc4f5e26cf52dcdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}